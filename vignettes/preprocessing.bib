@Article{towsey2018,
AUTHOR = {Towsey, Michael Towsey and Znidersic, Elizabeth Znidersic and Broken-Brow, Julie Broken-Brow and Indraswari, Karlina Indraswari and Watson, David M. Watson and Phillips, Yvonne Phillips and Truskinger, Anthony Truskinger and Roe, Paul Roe},
TITLE = {Long-duration, false-colour spectrograms for detecting species in large audio data-sets},
JOURNAL = {Journal of Ecoacoustics},
VOLUME = {2},
YEAR = {2018},
NUMBER = {1},
PAGES = {1--1},
URL = {https://jea.jams.pub/article/2/1/48},
ISSN = {2516-1466},
ABSTRACT = {Long-duration recordings of the natural environment have many advantages in passive monitoring of animal diversity. Technological advances now enable the collection of far more audio than can be listened to, necessitating the development of scalable approaches for distinguishing signal from noise. Computational methods, using automated species recognisers, have improved in accuracy but require considerable coding expertise. The content of environmental recordings is unconstrained, and the creation of labelled datasets required for machine learning purposes is a time-consuming, expensive enterprise. Here, we describe a visual approach to the analysis of environmental recordings using long-duration false-colour (LDFC) spectrograms, prepared from combinations of spectral indices. The technique was originally developed to visualize 24-hour “soundscapes.” A soundscape is an ecoacoustics concept that encompasses the totality of sound in an ecosystem. We describe three case studies to demonstrate how LDFC spectrograms can be used, not only to study soundscapes, but also to monitor individual species within them. In the first case, LDFC spectrograms help to solve a “needle in the haystack” problem—to locate vocalisations of the furtive Lewin’s Rail (Tasmanian), Lewinia pectoralis brachipus. We extend the technique by using a machine learning method to scan multiple days of LDFC spectrograms. In the second case study, we demonstrate that frog choruses are easily identified in LDFC spectrograms because of their extended time-scale. Although calls of individual frogs are lost in the cacophony of sound, spectral indices can distinguish different chorus characteristics. Third, we demonstrate that the method can be extended to the detection of bat echolocation calls. By converting complex acoustic data into readily interpretable images, our practical approach bridges the gap between bioacoustics and ecoacoustics, encompassing temporal scales across three orders of magnitude. Using the one methodology, it is possible to monitor entire soundscapes and individual species within those soundscapes.},
DOI = {10.22261/JEA.IUSWUI}
}
